"""
çº§è”æ£€ç´¢è¯„æµ‹è„šæœ¬ - ä¿®å¤ç‰ˆ
ä¿®å¤äº† torch å¯¼å…¥é—®é¢˜
"""

import json
import time
import sqlite3
import faiss
import numpy as np
import re
import torch
from pathlib import Path
from tqdm import tqdm
from sentence_transformers import SentenceTransformer
from retrieval.approach0_hash import DualHashGenerator

# ==================== é…ç½® ====================
MODEL_NAME = 'math-similarity/Bert-MLM_arXiv-MP-class_zbMath'
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
DB_PATH = "artifacts/formula_index.db"
INDEX_PATH = "artifacts/vector_index_full_v3.faiss"
MAPPING_PATH = "artifacts/vector_id_mapping_v3.json"
LABEL_PATH = "data/processed/relevance_labels.json"
QUERY_PATH = "data/processed/queries_full.json"

# Stage 1 å€™é€‰é›†å¤§å°ï¼ˆå¯è°ƒèŠ‚å®éªŒå‚æ•°ï¼‰
STAGE1_TOP_K = 10000
# æœ€ç»ˆè¿”å›ç»“æœæ•°
FINAL_TOP_K = 1000

# =========================== ç»Ÿä¸€æ¸…æ´—å‡½æ•° ===========================
def clean_latex(latex_str):
    if not latex_str: 
        return ""
    latex_str = re.sub(r'\$\$?|\\\[|\\\]', '', latex_str)
    latex_str = re.sub(r'\\dfrac|\\tfrac', r'\\frac', latex_str)
    latex_str = re.sub(r'\\left|\\right', '', latex_str)
    latex_str = re.sub(r'\s+', ' ', latex_str.strip())
    return latex_str.lower()

# =========================== çº§è”æ£€ç´¢å¼•æ“ ===========================
class CascadedRetriever:
    def __init__(self):
        print(f"ğŸ“¦ æ­£åœ¨åŠ è½½çº§è”æ£€ç´¢ç³»ç»Ÿ...")
        
        # Stage 1: å“ˆå¸Œæ£€ç´¢
        print(f"   [Stage 1] åŠ è½½å“ˆå¸Œæ•°æ®åº“...")
        self.conn = sqlite3.connect(DB_PATH)
        self.hash_gen = DualHashGenerator()
        
        # Stage 2: å‘é‡æ£€ç´¢
        print(f"   [Stage 2] åŠ è½½å‘é‡æ¨¡å‹ä¸ç´¢å¼•...")
        self.model = SentenceTransformer(MODEL_NAME, device=DEVICE)
        self.index = faiss.read_index(INDEX_PATH)
        
        with open(MAPPING_PATH, 'r') as f:
            self.fids = json.load(f)
        
        # åˆ›å»ºIDåˆ°ç´¢å¼•ä½ç½®çš„åå‘æ˜ å°„
        self.fid_to_idx = {fid: idx for idx, fid in enumerate(self.fids)}
        
        print(f"   âœ… çº§è”ç³»ç»ŸåŠ è½½å®Œæˆ")
        print(f"      - æ•°æ®åº“: {DB_PATH}")
        print(f"      - å‘é‡ç´¢å¼•: {self.index.ntotal:,} æ¡")

    def retrieve(self, query_latex, use_cascade=True):
        """
        æ‰§è¡Œçº§è”æ£€ç´¢
        """
        timing = {}
        
        if use_cascade:
            # === Stage 1: å“ˆå¸Œè¿‡æ»¤ ===
            t0 = time.time()
            q_hash = self.hash_gen.generate_latex_hash(query_latex)
            
            cursor = self.conn.cursor()
            cursor.execute(
                'SELECT formula_id FROM formula_index WHERE h_latex = ? LIMIT ?',
                (q_hash, STAGE1_TOP_K)
            )
            stage1_ids = [row[0] for row in cursor.fetchall()]
            timing['stage1'] = time.time() - t0
            
            if not stage1_ids:
                use_cascade = False
            else:
                candidate_indices = [
                    self.fid_to_idx[str(fid)] 
                    for fid in stage1_ids 
                    if str(fid) in self.fid_to_idx
                ]
                
                if not candidate_indices:
                    use_cascade = False
        
        # === Stage 2: å‘é‡é‡æ’ ===
        t0 = time.time()
        query_emb = self.model.encode(
            [query_latex], 
            normalize_embeddings=True, 
            convert_to_numpy=True
        ).astype('float32')
        
        if use_cascade and 'candidate_indices' in locals():
            # çº§è”æ¨¡å¼
            candidate_vectors = np.vstack([
                self.index.reconstruct(idx) 
                for idx in candidate_indices
            ])
            
            similarities = np.dot(candidate_vectors, query_emb.T).flatten()
            top_indices = np.argsort(-similarities)[:FINAL_TOP_K]
            result_indices = [candidate_indices[i] for i in top_indices]
            result_distances = [similarities[i] for i in top_indices]
        else:
            # å…¨é‡æ¨¡å¼
            distances, indices = self.index.search(query_emb, FINAL_TOP_K)
            result_indices = indices[0].tolist()
            result_distances = distances[0].tolist()
        
        timing['stage2'] = time.time() - t0
        
        result_ids = [self.fids[idx] for idx in result_indices if idx != -1]
        
        return result_ids, timing, result_distances

    def __del__(self):
        if hasattr(self, 'conn'):
            self.conn.close()

# =========================== è¯„æµ‹å‡½æ•° ===========================
def run_cascaded_evaluation():
    """å¯¹æ¯”çº§è”æ¨¡å¼å’Œçº¯å‘é‡æ¨¡å¼"""
    
    # åŠ è½½æ•°æ®
    with open(QUERY_PATH, 'r') as f:
        queries_raw = json.load(f)
    
    queries = {}
    for qid, qdata in queries_raw.items():
        if isinstance(qdata, dict):
            latex = qdata.get('latex_norm') or qdata.get('latex', '')
        else:
            latex = qdata
        queries[qid] = clean_latex(latex)
    
    with open(LABEL_PATH, 'r') as f:
        relevance = json.load(f)
    
    # åˆå§‹åŒ–æ£€ç´¢å™¨
    retriever = CascadedRetriever()
    
    # å­˜å‚¨ç»“æœ
    results = {
        'cascade': {'recalls': [], 'times': []},
        'pure_vector': {'recalls': [], 'times': []}
    }
    
    print(f"\nğŸš€ å¼€å§‹çº§è”æ£€ç´¢è¯„æµ‹...")
    print(f"   æŸ¥è¯¢æ•°é‡: {len(queries)}")
    print(f"   Stage 1 å€™é€‰: {STAGE1_TOP_K}")
    print(f"   æœ€ç»ˆè¿”å›: {FINAL_TOP_K}")
    
    for topic_id, query_latex in tqdm(list(queries.items()), desc="Evaluating"):
        gt_docs = set(str(x) for x in relevance.get(topic_id, {}).keys())
        if not gt_docs:
            continue
        
        # æ¨¡å¼1: çº§è”æ£€ç´¢
        result_ids, timing, _ = retriever.retrieve(query_latex, use_cascade=True)
        retrieved_set = set(str(x) for x in result_ids)
        hits = len(gt_docs.intersection(retrieved_set))
        recall = hits / len(gt_docs)
        results['cascade']['recalls'].append(recall)
        results['cascade']['times'].append(timing)
        
        # æ¨¡å¼2: çº¯å‘é‡æ£€ç´¢
        result_ids, timing, _ = retriever.retrieve(query_latex, use_cascade=False)
        retrieved_set = set(str(x) for x in result_ids)
        hits = len(gt_docs.intersection(retrieved_set))
        recall = hits / len(gt_docs)
        results['pure_vector']['recalls'].append(recall)
        results['pure_vector']['times'].append(timing)
    
    # è¾“å‡ºç»“æœ
    print("\n" + "="*70)
    print(f"ğŸ† çº§è”æ£€ç´¢å¯¹æ¯”è¯„æµ‹ç»“æœ")
    print("="*70)
    
    for mode_name, mode_data in results.items():
        avg_recall = np.mean(mode_data['recalls']) * 100
        avg_time = np.mean([sum(t.values()) for t in mode_data['times']]) * 1000
        
        mode_title = 'çº§è”æ¨¡å¼ (Stage 1 + 2)' if mode_name == 'cascade' else 'çº¯å‘é‡æ¨¡å¼ (Stage 2 Only)'
        print(f"\n{mode_title}")
        print(f"   Mean Recall@{FINAL_TOP_K}: {avg_recall:.2f}%")
        print(f"   å¹³å‡æŸ¥è¯¢æ—¶é—´: {avg_time:.1f} ms")
        
        if mode_name == 'cascade' and mode_data['times']:
            stage1_time = np.mean([t.get('stage1', 0) for t in mode_data['times']]) * 1000
            stage2_time = np.mean([t.get('stage2', 0) for t in mode_data['times']]) * 1000
            print(f"      - Stage 1 (Hash): {stage1_time:.1f} ms")
            print(f"      - Stage 2 (Vector): {stage2_time:.1f} ms")
    
    print("="*70)
    
    # ä¿å­˜ç»“æœ
    results_path = Path("evaluation_results")
    results_path.mkdir(exist_ok=True)
    
    with open(results_path / "cascaded_comparison.json", 'w') as f:
        json.dump({
            mode: {
                'mean_recall': np.mean(data['recalls']) * 100,
                'std_recall': np.std(data['recalls']) * 100,
                'mean_time_ms': np.mean([sum(t.values()) for t in data['times']]) * 1000,
                'num_queries': len(data['recalls'])
            }
            for mode, data in results.items()
        }, f, indent=2)
    
    print(f"\nğŸ’¾ å¯¹æ¯”ç»“æœå·²ä¿å­˜è‡³: {results_path / 'cascaded_comparison.json'}")

if __name__ == "__main__":
    run_cascaded_evaluation()