import json
import faiss
import numpy as np
import hashlib
from tqdm import tqdm
from pathlib import Path
from retrieval.approach0_hash import DualHashGenerator, Approach0HashIndex

class AblationTester:
    def __init__(self):
        print("ğŸ“¦ æ­£åœ¨åŠ è½½æ¶ˆèå®éªŒæ‰€éœ€èµ„æº...")
        self.hash_gen = DualHashGenerator()
        self.h_index = Approach0HashIndex()
        self.h_index.load("artifacts/approach0_index.pkl")
        
        # ä»…åœ¨éœ€è¦å‘é‡è·¯æ—¶åŠ è½½ï¼ŒèŠ‚çœæ˜¾å­˜
        from sentence_transformers import SentenceTransformer
        self.model = SentenceTransformer('math-similarity/Bert-MLM_arXiv-MP-class_zbMath', device="cuda")
        self.v_index = faiss.read_index("artifacts/vector_index_full_v4.faiss")
        with open("artifacts/vector_id_mapping_v4.json", 'r') as f:
            self.v_mapping = json.load(f)
            
        with open("data/processed/queries_full.json", 'r') as f:
            self.queries = json.load(f) # æ³¨æ„ï¼šè¿™é‡Œå­˜çš„æ˜¯ç»è¿‡è§„èŒƒåŒ–çš„ï¼Œæˆ‘ä»¬éœ€è¦åŸå§‹æŸ¥è¯¢
        
        # é‡æ–°è¯»å–åŸå§‹æŸ¥è¯¢ TSVï¼Œä»¥æµ‹è¯• V1 (æœªè§„èŒƒåŒ–)
        self.raw_queries = self._load_raw_queries()
        with open("data/processed/relevance_labels.json", 'r') as f:
            self.relevance = json.load(f)

    def _load_raw_queries(self):
        import csv
        raw = {}
        with open("data/arqmath3/queries_arqmath3_task2.tsv", 'r', encoding='utf-8') as f:
            reader = csv.reader(f, delimiter='\t')
            for row in reader:
                if len(row) >= 2: raw[row[0].strip()] = row[1].strip()
        return raw

    def run_search(self, query_latex, use_norm=True, use_hash=True, use_vector=True):
        results = []
        seen = set()

        # 1. è§„èŒƒåŒ–å¤„ç†
        if use_norm:
            norm_latex, _ = self.hash_gen.clean_latex(query_latex)
        else:
            # V1: ä»…å»é™¤ä¸¤ç«¯çš„ $ å’Œç©ºæ ¼ï¼Œä¸è¿›è¡Œæ·±åº¦æ¸…æ´—
            norm_latex = query_latex.replace('$', '').strip()

        # 2. å“ˆå¸Œè·¯
        if use_hash:
            h_val = hashlib.md5(norm_latex.encode('utf-8')).hexdigest()
            for vid in self.h_index.search(h_val):
                if vid not in seen:
                    results.append(vid)
                    seen.add(vid)

        # 3. å‘é‡è·¯
        if use_vector:
            q_emb = self.model.encode([norm_latex], normalize_embeddings=True, convert_to_numpy=True)
            _, v_indices = self.v_index.search(q_emb.astype('float32'), 1000)
            for idx in v_indices[0]:
                if idx != -1:
                    vid = str(self.v_mapping[idx])
                    if vid not in seen:
                        results.append(vid)
                        seen.add(vid)
        
        return results[:1000]

    def evaluate_variant(self, name, use_norm, use_hash, use_vector):
        print(f"\nğŸ§ª æ­£åœ¨æµ‹è¯•å˜ä½“ {name}...")
        recalls, mrr_scores = [], []
        
        for qid, raw_latex in tqdm(self.raw_queries.items(), desc=f"{name}"):
            gt = set(str(k) for k in self.relevance.get(qid, {}).keys())
            if not gt: continue
            
            results = self.run_search(raw_latex, use_norm, use_hash, use_vector)
            
            # è®¡ç®— Recall
            hits = gt.intersection(set(results))
            recalls.append(len(hits)/len(gt))
            
            # è®¡ç®— MRR
            mrr = 0
            for i, r in enumerate(results):
                if r in gt:
                    mrr = 1/(i+1)
                    break
            mrr_scores.append(mrr)
            
        return np.mean(recalls), np.mean(mrr_scores)

    def start_ablation(self):
        variants = [
            ("V1 (Baseline: Raw Hash)", False, True, False),
            ("V2 (Normalized Hash Only)", True, True, False),
            ("V3 (Semantic Vector Only)", True, False, True),
            ("V4 (Proposed Hybrid)", True, True, True),
        ]
        
        summary = []
        for name, norm, h_path, v_path in variants:
            r, m = self.evaluate_variant(name, norm, h_path, v_path)
            summary.append({"Variant": name, "Recall@1000": r, "MRR": m})
        
        print("\n" + "="*60)
        print("ğŸ“Š æ¶ˆèå®éªŒæœ€ç»ˆå®æµ‹ç»“æœ")
        print("="*60)
        print(f"{'Variant':<30} | {'Recall@1000':<12} | {'MRR':<8}")
        print("-" * 60)
        for row in summary:
            print(f"{row['Variant']:<30} | {row['Recall@1000']:>11.2%} | {row['MRR']:>8.4f}")
        print("="*60)

if __name__ == "__main__":
    tester = AblationTester()
    tester.start_ablation()