import json
import re
from pathlib import Path
from retrieval.approach0_hash import DualHashGenerator

# =========================== å¿…é¡»ä¸ prepare è„šæœ¬å®Œå…¨ä¸€è‡´çš„æ¸…æ´—å‡½æ•° ===========================
def clean_latex(latex_str):
    if not latex_str: return ""
    latex_str = re.sub(r'\$\$?|\\\[|\\\]', '', latex_str)
    latex_str = re.sub(r'\\dfrac|\\tfrac', r'\\frac', latex_str)
    latex_str = re.sub(r'\\left|\\right', '', latex_str)
    latex_str = re.sub(r'\s+', ' ', latex_str.strip())
    # æŒ‰ç…§æœ€æ–°çš„å»ºè®®ï¼Œä¸ä½¿ç”¨ .lower()
    return latex_str

def debug_alignment():
    print("ğŸ§ª --- å¯åŠ¨ Hash å¯¹é½æ€§æ·±åº¦è¯Šæ–­ --- ğŸ§ª\n")
    
    # 1. åŠ è½½æ‰€æœ‰ç›¸å…³æ–‡ä»¶
    try:
        with open("data/processed/queries_full.json", 'r') as f:
            queries = json.load(f)
        with open("data/processed/formulas.json", 'r') as f:
            corpus = json.load(f)
        with open("data/processed/relevance_labels.json", 'r') as f:
            relevance = json.load(f)
    except FileNotFoundError as e:
        print(f"âŒ ç¼ºå°‘å¿…è¦æ–‡ä»¶: {e}")
        return

    hash_gen = DualHashGenerator()
    found_case = False

    # 2. éå†æŸ¥è¯¢ï¼Œå¯»æ‰¾ä¸€ä¸ªâ€œæœ¬è¯¥åŒ¹é…â€çš„æ¡ˆä¾‹
    for topic_id, query_latex in queries.items():
        if topic_id not in relevance: continue
        
        # è·å–è¯¥æŸ¥è¯¢çš„æ‰€æœ‰æ ‡å‡†ç­”æ¡ˆ ID
        gt_ids = list(relevance[topic_id].keys())
        
        # å¯»æ‰¾åº“ä¸­å­˜åœ¨çš„ç¬¬ä¸€ä¸ªæ ‡å‡†ç­”æ¡ˆ
        for gt_id in gt_ids:
            gt_id_str = str(gt_id)
            if gt_id_str in corpus:
                found_case = True
                corpus_item = corpus[gt_id_str]
                corpus_latex = corpus_item['latex_norm']
                
                print(f"ğŸ“ [æ¡ˆä¾‹åˆ†æ] Topic: {topic_id} -> Ground Truth ID: {gt_id_str}")
                print("-" * 60)
                
                # --- æ ¸å¿ƒå¯¹æ¯”ï¼šå­—ç¬¦ä¸²çº§ ---
                print(f"ã€æŸ¥è¯¢ç«¯ LaTeX (TSV)ã€‘:  {query_latex}")
                print(f"ã€è¯­æ–™ç«¯ LaTeX (JSON)ã€‘: {corpus_latex}")
                
                if query_latex == corpus_latex:
                    print("âœ… å­—ç¬¦ä¸²å®Œå…¨å¯¹é½ (String Match: OK)")
                else:
                    print("âŒ å­—ç¬¦ä¸²ä¸ä¸€è‡´ï¼(String Match: FAILED)")
                    # å¯»æ‰¾ç¬¬ä¸€ä¸ªä¸ä¸€è‡´çš„å­—ç¬¦
                    for i, (c1, c2) in enumerate(zip(query_latex, corpus_latex)):
                        if c1 != c2:
                            print(f"   ğŸ’¡ å·®å¼‚ç‚¹å‡ºç°åœ¨ç¬¬ {i} ä½: '{c1}' vs '{c2}'")
                            break
                
                # --- æ ¸å¿ƒå¯¹æ¯”ï¼šå“ˆå¸Œçº§ ---
                q_hash = hash_gen.generate_latex_hash(query_latex)
                c_hash = hash_gen.generate_latex_hash(corpus_latex)
                
                print(f"\nã€æŸ¥è¯¢ç«¯ Hashã€‘: {q_hash}")
                print(f"ã€è¯­æ–™ç«¯ Hashã€‘: {c_hash}")
                
                if q_hash == c_hash:
                    print("âœ… å“ˆå¸Œç”Ÿæˆä¸€è‡´ (Hash Match: OK)")
                else:
                    print("âŒ å“ˆå¸Œä¸åŒ¹é…ï¼è¿™è¯´æ˜ DualHashGenerator å†…éƒ¨å­˜åœ¨ä¸ç¨³å®šé€»è¾‘ã€‚")

                print("-" * 60)
                # æ¯ä¸ªæŸ¥è¯¢åªçœ‹ç¬¬ä¸€ä¸ªå‘½ä¸­çš„ GTï¼Œæˆ–è€…åªçœ‹å‰å‡ ä¸ªæ¡ˆä¾‹
                break 
        
        if found_case: break # è¯Šæ–­å‡ºä¸€ä¸ªå…¸å‹æ¡ˆä¾‹å³å¯

    if not found_case:
        print("âš ï¸ è­¦å‘Šï¼šåœ¨å½“å‰ formulas.json ä¸­æœªæ‰¾åˆ°ä»»ä½•æ ‡æ³¨çš„æ ‡å‡†ç­”æ¡ˆ IDã€‚")
        print("ğŸ’¡ å»ºè®®ï¼šè¯·ç¡®è®¤ prepare_final_arqmath.py æ˜¯å¦å¤„ç†äº†åŒ…å«æ ‡å‡†ç­”æ¡ˆçš„é‚£äº›åˆ†ç‰‡ã€‚")

if __name__ == "__main__":
    debug_alignment()