import json
import pickle
import faiss
import numpy as np
from pathlib import Path
from retrieval.approach0_hash import DualHashGenerator, Approach0HashIndex

# é…ç½®è·¯å¾„
FORMULAS_JSON = "data/processed/formulas.json"
QUERIES_JSON = "data/processed/queries_full.json"
LABELS_JSON = "data/processed/relevance_labels.json"

def analyze_errors():
    print("ğŸ” å¯åŠ¨é”™è¯¯åˆ†æç³»ç»Ÿ (Recall=0 æ¡ˆä¾‹æå–)...")
    
    # 1. åŠ è½½èµ„æº
    with open(FORMULAS_JSON, 'r') as f:
        corpus = json.load(f)
    with open(QUERIES_JSON, 'r') as f:
        queries = json.load(f)
    with open(LABELS_JSON, 'r') as f:
        relevance = json.load(f)
    
    # å‡è®¾ä½ å·²ç»è¿è¡Œè¿‡è¯„æµ‹ï¼Œè¿™é‡Œæˆ‘ä»¬é‡æ–°è¿è¡Œé€»è¾‘å¯»æ‰¾å¤±è´¥è€…
    # (ä¸ºäº†ç®€åŒ–ï¼Œè¿™é‡Œç›´æ¥å¯¹æ¯” relevance ä¸­çš„ ID æ˜¯å¦åœ¨ Top-1000 é€»è¾‘å¤–)
    
    # æˆ‘ä»¬å‡è®¾ä½¿ç”¨ä½ ä¹‹å‰çš„ Hybrid Evaluator é€»è¾‘è¿›è¡Œæ¨¡æ‹Ÿ
    from evaluation.final_hybrid_evaluator import HybridEvaluator
    evaluator = HybridEvaluator()
    
    failed_cases = []

    print("ğŸ§ª æ­£åœ¨æ‰«æå¤±è´¥æŸ¥è¯¢...")
    for qid, query_latex in queries.items():
        gt_dict = relevance.get(qid, {})
        if not gt_dict: continue
        
        gt_ids = set(str(vid) for vid in gt_dict.keys())
        results = evaluator.search_single(query_latex)
        
        hits = gt_ids.intersection(set(results))
        if len(hits) == 0:
            failed_cases.append({
                "qid": qid,
                "query": query_latex,
                "gt_sample_ids": list(gt_ids)[:3] # å–å‰3ä¸ªç­”æ¡ˆåšå¯¹æ¯”
            })

    # 2. è¾“å‡ºåˆ†ææŠ¥å‘Š
    report_path = "evaluation/error_analysis_report.txt"
    with open(report_path, "w", encoding="utf-8") as f:
        f.write(f"ğŸ“Š é”™è¯¯åˆ†ææŠ¥å‘Š (Total Failed: {len(failed_cases)})\n")
        f.write("="*80 + "\n\n")
        
        for case in failed_cases:
            f.write(f"âŒ Topic ID: {case['qid']}\n")
            f.write(f"   [Query LaTeX]: {case['query']}\n")
            f.write(f"   [Ground Truths]:\n")
            
            for g_id in case['gt_sample_ids']:
                if g_id in corpus:
                    gt_latex = corpus[g_id]['latex']
                    f.write(f"      - ID {g_id}: {gt_latex}\n")
                else:
                    f.write(f"      - ID {g_id}: âš ï¸ åº“ä¸­ä¸å­˜åœ¨ (Coverage Error)\n")
            f.write("-" * 80 + "\n")

    print(f"âœ… åˆ†æå®Œæˆï¼æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_path}")
    print(f"ğŸ’¡ æç¤ºï¼šè¯·æ‰“å¼€è¯¥æ–‡ä»¶ï¼Œè‚‰çœ¼æ¯”å¯¹ Query å’Œ GT çš„ LaTeX å†™æ³•å·®å¼‚ã€‚")

if __name__ == "__main__":
    analyze_errors()