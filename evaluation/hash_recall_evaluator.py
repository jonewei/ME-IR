import json
import sqlite3
import re
from pathlib import Path
from tqdm import tqdm
from retrieval.approach0_hash import DualHashGenerator

# ==================== é…ç½® ====================
DB_PATH = "artifacts/formula_index.db"
LABEL_PATH = "data/processed/relevance_labels.json"
QUERY_PATH = "data/processed/queries_full.json"
FORMULAS_PATH = "data/processed/formulas.json"
TOP_K = 10000  # Stage 1é€šå¸¸å¬å›æ›´å¤šå€™é€‰

# =========================== ç»Ÿä¸€çš„LaTeXæ¸…æ´—å‡½æ•° ===========================
def clean_latex(latex_str):
    """å¿…é¡»ä¸å…¶ä»–è„šæœ¬ä¿æŒä¸€è‡´"""
    if not latex_str: 
        return ""
    latex_str = re.sub(r'\$\$?|\\\[|\\\]', '', latex_str)
    latex_str = re.sub(r'\\dfrac|\\tfrac', r'\\frac', latex_str)
    latex_str = re.sub(r'\\left|\\right', '', latex_str)
    latex_str = re.sub(r'\s+', ' ', latex_str.strip())
    return latex_str.lower()

# =========================== Stage 1 è¯„æµ‹å¼•æ“ ===========================
class HashEvaluator:
    def __init__(self):
        print(f"ğŸ“¦ æ­£åœ¨åŠ è½½Stage 1è¯„æµ‹ç¯å¢ƒ...")
        
        # åŠ è½½æ•°æ®åº“
        self.conn = sqlite3.connect(DB_PATH)
        self.hash_gen = DualHashGenerator()
        
        # åŠ è½½å…¬å¼å…ƒæ•°æ®ï¼ˆç”¨äºæå–DNAï¼‰
        print(f"   - æ­£åœ¨åŠ è½½å…¬å¼å…ƒæ•°æ®...")
        with open(FORMULAS_PATH, 'r') as f:
            self.formulas = json.load(f)
        
        # åŠ è½½æŸ¥è¯¢
        with open(QUERY_PATH, 'r') as f:
            queries_raw = json.load(f)
        
        self.queries = {}
        for qid, qdata in queries_raw.items():
            if isinstance(qdata, dict):
                latex = qdata.get('latex_norm') or qdata.get('latex', '')
            else:
                latex = qdata
            self.queries[qid] = clean_latex(latex)
        
        # åŠ è½½æ ‡å‡†ç­”æ¡ˆ
        with open(LABEL_PATH, 'r') as f:
            self.relevance = json.load(f)
        
        print(f"   âœ… åŠ è½½å®Œæˆ")
        print(f"      - æ•°æ®åº“: {DB_PATH}")
        print(f"      - æŸ¥è¯¢æ•°: {len(self.queries)}")
        print(f"      - å…¬å¼åº“: {len(self.formulas):,}")

    def search_by_hash(self, query_latex, query_topic_id=None):
        """
        ä½¿ç”¨LaTeXå“ˆå¸Œæ£€ç´¢
        æ³¨æ„ï¼šè¿™é‡Œåªä½¿ç”¨LaTeXå“ˆå¸Œï¼Œå› ä¸ºæŸ¥è¯¢æ²¡æœ‰MathML/DNAä¿¡æ¯
        """
        # ç”ŸæˆæŸ¥è¯¢çš„LaTeXå“ˆå¸Œ
        q_hash = self.hash_gen.generate_latex_hash(query_latex)
        
        # ä»æ•°æ®åº“æ£€ç´¢åŒ¹é…çš„å…¬å¼ID
        cursor = self.conn.cursor()
        cursor.execute(
            'SELECT formula_id FROM formula_index WHERE h_latex = ? LIMIT ?',
            (q_hash, TOP_K)
        )
        results = [row[0] for row in cursor.fetchall()]
        
        return results

    def run_evaluation(self):
        """æ‰§è¡ŒStage 1è¯„æµ‹"""
        
        recall_scores = []
        query_details = []
        
        print(f"\nğŸ” å¼€å§‹Stage 1 (å“ˆå¸Œæ£€ç´¢) è¯„æµ‹...")
        print(f"   å¬å›ä¸Šé™: Top-{TOP_K}")
        
        for topic_id, query_latex in tqdm(self.queries.items(), desc="Processing"):
            # è·å–æ ‡å‡†ç­”æ¡ˆ
            gt_docs = set(self.relevance.get(topic_id, {}).keys())
            if not gt_docs:
                continue
            
            # æ‰§è¡Œå“ˆå¸Œæ£€ç´¢
            retrieved_ids = self.search_by_hash(query_latex, topic_id)
            retrieved_set = set(str(x) for x in retrieved_ids)
            gt_set = set(str(x) for x in gt_docs)
            
            # è®¡ç®—Recall
            hits = len(gt_set.intersection(retrieved_set))
            recall = hits / len(gt_set) if len(gt_set) > 0 else 0
            
            recall_scores.append(recall)
            
            query_details.append({
                'topic_id': topic_id,
                'query': query_latex[:100],
                'gt_count': len(gt_set),
                'retrieved_count': len(retrieved_set),
                'hits': hits,
                'recall': recall
            })
        
        # è¾“å‡ºç»“æœ
        avg_recall = sum(recall_scores) / len(recall_scores) * 100 if recall_scores else 0
        
        print("\n" + "="*60)
        print(f"ğŸ† Stage 1 (ç»“æ„å“ˆå¸Œ) è¯„æµ‹ç»“æœ")
        print("="*60)
        print(f"æ£€ç´¢æ–¹æ³•: LaTeX Hash (MD5)")
        print(f"æ•°æ®åº“è§„æ¨¡: {len(self.formulas):,} æ¡å…¬å¼")
        print(f"æŸ¥è¯¢æ•°é‡: {len(recall_scores)}")
        print(f"-" * 60)
        print(f"Mean Recall@{TOP_K}: {avg_recall:.2f}%")
        print("="*60)
        
        # å¬å›ç‡åˆ†å¸ƒ
        print(f"\nğŸ“ˆ å¬å›ç‡åˆ†å¸ƒ:")
        bins = [0, 0.01, 0.1, 0.3, 0.5, 0.7, 1.0]
        bin_names = ["0%", "0-1%", "1-10%", "10-30%", "30-50%", "50-70%", "70-100%"]
        for i in range(len(bins)-1):
            count = sum(1 for r in recall_scores if bins[i] <= r < bins[i+1])
            pct = count / len(recall_scores) * 100
            print(f"   {bin_names[i+1]}: {count:3d} queries ({pct:5.1f}%)")
        
        # æœ€ä½³å’Œæœ€å·®æ¡ˆä¾‹
        sorted_details = sorted(query_details, key=lambda x: x['recall'], reverse=True)
        
        print(f"\nâœ… Top 3 æœ€ä½³å¬å›:")
        for d in sorted_details[:3]:
            print(f"   [{d['topic_id']}] Recall: {d['recall']*100:.1f}% ({d['hits']}/{d['gt_count']})")
            print(f"      Query: {d['query']}")
        
        print(f"\nâŒ Top 3 æœ€å·®å¬å›:")
        for d in sorted_details[-3:]:
            print(f"   [{d['topic_id']}] Recall: {d['recall']*100:.1f}% ({d['hits']}/{d['gt_count']})")
            print(f"      Query: {d['query']}")
        
        # ä¿å­˜ç»“æœ
        results_path = Path("evaluation_results")
        results_path.mkdir(exist_ok=True)
        
        with open(results_path / "hash_recall_details.json", 'w') as f:
            json.dump({
                'summary': {
                    'mean_recall': avg_recall,
                    'num_queries': len(recall_scores),
                    'top_k': TOP_K
                },
                'details': query_details
            }, f, indent=2)
        
        print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜è‡³: {results_path / 'hash_recall_details.json'}")
        
        return avg_recall

    def __del__(self):
        if hasattr(self, 'conn'):
            self.conn.close()

if __name__ == "__main__":
    evaluator = HashEvaluator()
    evaluator.run_evaluation()