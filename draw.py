import json
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from matplotlib.patches import Circle, FancyBboxPatch
from collections import defaultdict

# è®¾ç½®å­¦æœ¯é£Žæ ¼
plt.rcParams['font.sans-serif'] = ['DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
sns.set_theme(style="white")

def analyze_noise_wall():
    """åˆ†æžå¹¶å¯è§†åŒ– ARQMath-3 çš„çœŸå®žè¯­ä¹‰å™ªå£°å¢™"""
    
    # ========== åŠ è½½æ•°æ® ==========
    print("ðŸ“‚ åŠ è½½æ•°æ®...")
    with open("data/qrel_76_expert.json", "r") as f:
        qrel = json.load(f)
    
    with open("results/raw_sem_scores.json", "r") as f:
        sem_scores = json.load(f)
    
    # ========== ç»Ÿè®¡åˆ†æž ==========
    print("ðŸ“Š ç»Ÿè®¡åˆ†æžä¸­...")
    
    stats = {
        'avg_top1_sim': [],
        'avg_top10_sim': [],
        'avg_top100_sim': [],
        'truth_avg_rank': [],
        'truth_avg_sim': [],
        'noise_density': []
    }
    
    for qid in qrel.keys():
        if qid not in sem_scores:
            continue
        
        # èŽ·å–çœŸå€¼ ID
        truth_ids = set(qrel[qid].keys())
        
        # èŽ·å–å€™é€‰åˆ†æ•°ï¼ˆå·²æŽ’åºï¼‰
        candidates = sem_scores[qid]
        sorted_candidates = sorted(candidates.items(), key=lambda x: x[1], reverse=True)
        
        # Top-K å¹³å‡ç›¸ä¼¼åº¦
        stats['avg_top1_sim'].append(sorted_candidates[0][1])
        stats['avg_top10_sim'].append(np.mean([s for _, s in sorted_candidates[:10]]))
        stats['avg_top100_sim'].append(np.mean([s for _, s in sorted_candidates[:100]]))
        
        # çœŸå€¼çš„æŽ’åå’Œåˆ†æ•°
        truth_ranks = []
        truth_sims = []
        for rank, (fid, sim) in enumerate(sorted_candidates, 1):
            if fid in truth_ids:
                truth_ranks.append(rank)
                truth_sims.append(sim)
        
        if truth_ranks:
            stats['truth_avg_rank'].append(np.mean(truth_ranks))
            stats['truth_avg_sim'].append(np.mean(truth_sims))
        
        # å™ªå£°å¯†åº¦ï¼ˆç›¸ä¼¼åº¦ > 0.94 çš„æ¯”ä¾‹ï¼‰
        high_sim_count = sum(1 for _, s in sorted_candidates[:100] if s > 0.94)
        stats['noise_density'].append(high_sim_count / 100)
    
    # ========== é€‰æ‹©æœ€å…·ä»£è¡¨æ€§çš„æŸ¥è¯¢ ==========
    # é€‰æ‹©çœŸå€¼æŽ’åæœ€é åŽçš„æŸ¥è¯¢ï¼ˆå™ªå£°å¢™æœ€ä¸¥é‡ï¼‰
    worst_qid = None
    worst_rank = 0
    
    for qid in qrel.keys():
        if qid not in sem_scores:
            continue
        
        truth_ids = set(qrel[qid].keys())
        candidates = sem_scores[qid]
        sorted_candidates = sorted(candidates.items(), key=lambda x: x[1], reverse=True)
        
        for rank, (fid, sim) in enumerate(sorted_candidates, 1):
            if fid in truth_ids:
                if rank > worst_rank:
                    worst_rank = rank
                    worst_qid = qid
                break
    
    print(f"\nðŸŽ¯ é€‰æ‹©æœ€å…·ä»£è¡¨æ€§çš„æŸ¥è¯¢: {worst_qid}")
    print(f"   çœŸå€¼æœ€å·®æŽ’å: #{worst_rank}")
    
    # ========== ç»˜åˆ¶å¯è§†åŒ– ==========
    fig = plt.figure(figsize=(16, 10))
    gs = fig.add_gridspec(2, 2, hspace=0.3, wspace=0.3)
    
    # --- å­å›¾ 1: å•æŸ¥è¯¢å™ªå£°å¢™ ---
    ax1 = fig.add_subplot(gs[0, :])
    draw_single_query_noise_wall(ax1, worst_qid, qrel, sem_scores)
    
    # --- å­å›¾ 2: å…¨å±€å™ªå£°å¯†åº¦åˆ†å¸ƒ ---
    ax2 = fig.add_subplot(gs[1, 0])
    draw_noise_density_distribution(ax2, stats)
    
    # --- å­å›¾ 3: çœŸå€¼æ·¹æ²¡ç»Ÿè®¡ ---
    ax3 = fig.add_subplot(gs[1, 1])
    draw_truth_burial_stats(ax3, stats)
    
    # ========== ä¿å­˜ ==========
    plt.savefig("draw/ARQMath3_Real_Noise_Wall_Analysis.svg", 
                format='svg', bbox_inches='tight', dpi=300)
    plt.savefig("draw/ARQMath3_Real_Noise_Wall_Analysis.png", 
                format='png', bbox_inches='tight', dpi=300)
    
    print("\nâœ… å¯è§†åŒ–å·²ä¿å­˜:")
    print("   ðŸ“„ SVG: draw/ARQMath3_Real_Noise_Wall_Analysis.svg")
    print("   ðŸ–¼ï¸  PNG: draw/ARQMath3_Real_Noise_Wall_Analysis.png")
    
    # ========== æ‰“å°ç»Ÿè®¡æ‘˜è¦ ==========
    print("\n" + "="*60)
    print("ðŸ“ˆ ARQMath-3 è¯­ä¹‰å™ªå£°å¢™ç»Ÿè®¡æ‘˜è¦")
    print("="*60)
    print(f"å¹³å‡ Top-1 ç›¸ä¼¼åº¦:   {np.mean(stats['avg_top1_sim']):.4f}")
    print(f"å¹³å‡ Top-10 ç›¸ä¼¼åº¦:  {np.mean(stats['avg_top10_sim']):.4f}")
    print(f"å¹³å‡ Top-100 ç›¸ä¼¼åº¦: {np.mean(stats['avg_top100_sim']):.4f}")
    print(f"çœŸå€¼å¹³å‡æŽ’å:        #{np.mean(stats['truth_avg_rank']):.1f}")
    print(f"çœŸå€¼å¹³å‡ç›¸ä¼¼åº¦:      {np.mean(stats['truth_avg_sim']):.4f}")
    print(f"å™ªå£°å¯†åº¦ (Sim>0.94): {np.mean(stats['noise_density'])*100:.1f}%")
    print("="*60)
    
    plt.show()


def draw_single_query_noise_wall(ax, qid, qrel, sem_scores):
    """ç»˜åˆ¶å•ä¸ªæŸ¥è¯¢çš„å™ªå£°å¢™"""
    
    truth_ids = set(qrel[qid].keys())
    candidates = sem_scores[qid]
    sorted_candidates = sorted(candidates.items(), key=lambda x: x[1], reverse=True)
    
    # å– Top-500
    top500 = sorted_candidates[:500]
    ranks = np.arange(1, 501)
    sims = [s for _, s in top500]
    
    # æ ‡è®°çœŸå€¼ä½ç½®
    truth_ranks = []
    truth_sims = []
    for rank, (fid, sim) in enumerate(top500, 1):
        if fid in truth_ids:
            truth_ranks.append(rank)
            truth_sims.append(sim)
    
    # ç»˜åˆ¶å™ªå£°å¢™
    ax.fill_between(ranks, sims, alpha=0.3, color='red', label='Noise Wall')
    ax.plot(ranks, sims, color='darkred', linewidth=2, alpha=0.7)
    
    # æ ‡è®°çœŸå€¼
    if truth_ranks:
        ax.scatter(truth_ranks, truth_sims, 
                  c='gold', s=200, marker='*', 
                  edgecolors='black', linewidths=2,
                  label=f'Ground Truth (n={len(truth_ranks)})',
                  zorder=10)
    
    # é˜ˆå€¼çº¿
    ax.axhline(y=0.94, color='orange', linestyle='--', 
               linewidth=2, alpha=0.8, label='High Similarity Threshold (0.94)')
    
    ax.set_title(f'A. Semantic Noise Wall for Query {qid}\n'
                 f'Top-500 Candidates | Avg Sim: {np.mean(sims):.4f}',
                 fontsize=14, fontweight='bold')
    ax.set_xlabel('Rank', fontsize=12)
    ax.set_ylabel('Cosine Similarity', fontsize=12)
    ax.set_ylim(0.85, 1.0)
    ax.legend(loc='upper right', fontsize=10)
    ax.grid(True, linestyle=':', alpha=0.4)


def draw_noise_density_distribution(ax, stats):
    """ç»˜åˆ¶å™ªå£°å¯†åº¦åˆ†å¸ƒ"""
    
    densities = np.array(stats['noise_density']) * 100
    
    ax.hist(densities, bins=20, color='coral', alpha=0.7, edgecolor='black')
    ax.axvline(x=np.mean(densities), color='red', linestyle='--', 
               linewidth=2, label=f'Mean: {np.mean(densities):.1f}%')
    
    ax.set_title('B. Noise Density Distribution\n(Sim > 0.94 in Top-100)',
                 fontsize=13, fontweight='bold')
    ax.set_xlabel('Noise Density (%)', fontsize=11)
    ax.set_ylabel('Number of Queries', fontsize=11)
    ax.legend(fontsize=10)
    ax.grid(True, linestyle=':', alpha=0.4)


def draw_truth_burial_stats(ax, stats):
    """ç»˜åˆ¶çœŸå€¼æ·¹æ²¡ç»Ÿè®¡"""
    
    ranks = stats['truth_avg_rank']
    sims = stats['truth_avg_sim']
    
    scatter = ax.scatter(ranks, sims, c=ranks, cmap='RdYlGn_r', 
                        s=100, alpha=0.6, edgecolors='black')
    
    ax.axhline(y=np.mean(stats['avg_top10_sim']), 
               color='blue', linestyle='--', alpha=0.5,
               label='Avg Top-10 Similarity')
    
    ax.set_title('C. Ground Truth Burial Analysis\n'
                 'Rank vs Similarity',
                 fontsize=13, fontweight='bold')
    ax.set_xlabel('Average Rank of Ground Truth', fontsize=11)
    ax.set_ylabel('Average Similarity', fontsize=11)
    ax.legend(fontsize=10)
    ax.grid(True, linestyle=':', alpha=0.4)
    
    cbar = plt.colorbar(scatter, ax=ax)
    cbar.set_label('Rank (worse â†’)', fontsize=10)


if __name__ == "__main__":
    analyze_noise_wall()
