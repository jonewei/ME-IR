"""
ğŸ”§ ä¿®å¤ç‰ˆå‘é‡ç´¢å¼•æ„å»ºè„šæœ¬ - æ— æ£€æŸ¥ç‚¹ç‰ˆæœ¬
é€‚ç”¨äºç£ç›˜ç©ºé—´æœ‰é™çš„æƒ…å†µï¼Œç›´æ¥æ„å»ºæœ€ç»ˆç´¢å¼•ï¼Œä¸ä¿å­˜ä¸­é—´æ£€æŸ¥ç‚¹
"""

import os
import json
import torch
import faiss
import numpy as np
from sentence_transformers import SentenceTransformer
from tqdm import tqdm
from pathlib import Path

# ==================== é…ç½®å‚æ•° ====================
MODEL_NAME = 'math-similarity/Bert-MLM_arXiv-MP-class_zbMath'
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
BATCH_SIZE = 512
ARTIFACTS_DIR = Path("artifacts")
INDEX_PATH = ARTIFACTS_DIR / "vector_index_full_v3.faiss"
MAPPING_PATH = ARTIFACTS_DIR / "vector_id_mapping_v3.json"

def build_index():
    """æ„å»ºå‘é‡ç´¢å¼•ï¼ˆæ— æ£€æŸ¥ç‚¹ï¼ŒèŠ‚çœç£ç›˜ç©ºé—´ï¼‰"""
    
    ARTIFACTS_DIR.mkdir(exist_ok=True)
    
    # 1. åŠ è½½æ¨¡å‹
    print(f"ğŸ¤– æ­£åœ¨åŠ è½½æ¨¡å‹: {MODEL_NAME}")
    print(f"   è®¾å¤‡: {DEVICE}")
    model = SentenceTransformer(MODEL_NAME, device=DEVICE)
    
    # 2. è¯»å–å…ƒæ•°æ®
    formulas_path = "data/processed/formulas.json"
    print(f"\nğŸ“– æ­£åœ¨è¯»å– {formulas_path}...")
    
    with open(formulas_path, 'r', encoding='utf-8') as f:
        corpus_dict = json.load(f)
    
    fids = list(corpus_dict.keys())
    formulas = [corpus_dict[fid]['latex_norm'] for fid in fids]
    
    print(f"âœ… åŠ è½½å®Œæˆï¼Œæ€»å…¬å¼æ•°: {len(fids):,}")
    
    # æ•°æ®è´¨é‡æ£€æŸ¥
    print(f"\nğŸ“Š æ•°æ®è´¨é‡æ£€æŸ¥:")
    print(f"   å‰5ä¸ªå…¬å¼ç¤ºä¾‹:")
    for i in range(min(5, len(formulas))):
        print(f"   [{fids[i]}]: {formulas[i][:80]}...")
    
    has_dollar = sum(1 for f in formulas[:1000] if '$' in f)
    if has_dollar > 0:
        print(f"   âš ï¸  è­¦å‘Š: å‰1000æ¡ä¸­æœ‰ {has_dollar} æ¡åŒ…å«'$'ç¬¦å·")
        print(f"   âš ï¸  è¯·ç¡®è®¤å·²ä½¿ç”¨ä¿®å¤ç‰ˆçš„prepareè„šæœ¬é‡æ–°ç”Ÿæˆformulas.jsonï¼")
    else:
        print(f"   âœ… æ¸…æ´—æ£€æŸ¥é€šè¿‡ï¼šæ— $ç¬¦å·æ®‹ç•™")

    # 3. åˆå§‹åŒ– Faiss ç´¢å¼•
    dim = 768
    print(f"\nğŸ”¨ åˆå§‹åŒ– Faiss ç´¢å¼• (IndexFlatIP, dim={dim})")
    index = faiss.IndexFlatIP(dim)
    
    # 4. é¢„ä¼°å†…å­˜å’Œç£ç›˜éœ€æ±‚
    estimated_memory_gb = len(formulas) * dim * 4 / (1024**3)
    print(f"\nğŸ’¾ èµ„æºéœ€æ±‚é¢„ä¼°:")
    print(f"   - å†…å­˜å ç”¨: {estimated_memory_gb:.2f} GB")
    print(f"   - æœ€ç»ˆç´¢å¼•æ–‡ä»¶: {estimated_memory_gb:.2f} GB")
    print(f"   - æ˜ å°„æ–‡ä»¶: <1 MB")
    
    # 5. æ‰¹é‡ç¼–ç ä¸æ·»åŠ ï¼ˆæ— æ£€æŸ¥ç‚¹ï¼‰
    print(f"\nğŸš€ å¼€å§‹å‘é‡åŒ– (Batch Size: {BATCH_SIZE})...")
    print(f"   âš ï¸  ç£ç›˜ç©ºé—´æœ‰é™ï¼Œä¸ä¿å­˜æ£€æŸ¥ç‚¹")
    print(f"   âš ï¸  å¦‚æœä¸­æ–­ï¼Œéœ€è¦é‡æ–°è¿è¡Œæ•´ä¸ªè„šæœ¬")
    
    chunk_size = 50000  # æ¯æ¬¡å¤„ç†5ä¸‡æ¡
    total_added = 0
    
    for i in tqdm(range(0, len(formulas), chunk_size), desc="æ€»è¿›åº¦"):
        chunk_formulas = formulas[i : i + chunk_size]
        
        # ç¼–ç 
        embeddings = model.encode(
            chunk_formulas,
            batch_size=BATCH_SIZE,
            show_progress_bar=False,
            normalize_embeddings=True,
            convert_to_numpy=True
        )
        
        # æ·»åŠ åˆ°ç´¢å¼•
        index.add(embeddings.astype('float32'))
        total_added += len(embeddings)
        
        # æ¯å¤„ç†50ä¸‡æ¡æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
        if total_added % 500000 == 0:
            print(f"\n   âœ… å·²å¤„ç† {total_added:,} / {len(formulas):,} ({total_added/len(formulas)*100:.1f}%)")

    # 6. æœ€ç»ˆä¿å­˜
    print(f"\nğŸ’¾ æ­£åœ¨ä¿å­˜æœ€ç»ˆç´¢å¼•...")
    print(f"   è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…...")
    
    try:
        faiss.write_index(index, str(INDEX_PATH))
        print(f"   âœ… ç´¢å¼•ä¿å­˜æˆåŠŸ: {INDEX_PATH}")
    except Exception as e:
        print(f"   âŒ ç´¢å¼•ä¿å­˜å¤±è´¥: {e}")
        print(f"   ğŸ’¡ å¯èƒ½åŸå› : ç£ç›˜ç©ºé—´ä¸è¶³")
        print(f"   ğŸ’¡ éœ€è¦è‡³å°‘ {estimated_memory_gb:.1f} GB å¯ç”¨ç©ºé—´")
        return False
    
    with open(MAPPING_PATH, 'w') as f:
        json.dump(fids, f)
    
    print(f"   âœ… æ˜ å°„ä¿å­˜æˆåŠŸ: {MAPPING_PATH}")
    
    # 7. éªŒè¯
    print(f"\nâœ… ç´¢å¼•æ„å»ºå®Œæˆï¼")
    print(f"   ç´¢å¼•æ–‡ä»¶: {INDEX_PATH}")
    print(f"   æ˜ å°„æ–‡ä»¶: {MAPPING_PATH}")
    print(f"   æ€»å‘é‡æ•°: {index.ntotal:,}")
    print(f"   ç´¢å¼•ç±»å‹: {type(index).__name__}")
    print(f"   ç»´åº¦: {index.d}")
    
    # 8. å¿«é€Ÿæµ‹è¯•
    print(f"\nğŸ§ª å¿«é€Ÿæµ‹è¯•...")
    test_query = formulas[0]
    test_emb = model.encode([test_query], normalize_embeddings=True, convert_to_numpy=True)
    D, I = index.search(test_emb.astype('float32'), 5)
    
    print(f"   æŸ¥è¯¢: {test_query[:50]}...")
    print(f"   Top-1 è·ç¦»: {D[0][0]:.4f} (åº”è¯¥æ¥è¿‘1.0)")
    print(f"   Top-1 ID: {fids[I[0][0]]} (åº”è¯¥æ˜¯è‡ªå·±)")
    
    if D[0][0] > 0.99:
        print(f"   âœ… ç´¢å¼•éªŒè¯é€šè¿‡ï¼")
        return True
    else:
        print(f"   âš ï¸  è­¦å‘Š: Top-1ç›¸ä¼¼åº¦å¼‚å¸¸ï¼Œè¯·æ£€æŸ¥normalizeè®¾ç½®")
        return False

if __name__ == "__main__":
    success = build_index()
    if not success:
        print("\nâŒ æ„å»ºå¤±è´¥ï¼è¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
        exit(1)
    else:
        print("\nğŸ‰ æ„å»ºæˆåŠŸï¼å¯ä»¥ç»§ç»­è¿è¡Œè¯„æµ‹è„šæœ¬")