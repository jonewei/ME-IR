"""
Step 2: Build Approach0 structural index (Dual-Hash Version)

This script:
1. Loads combined formulas (Latex + MathML) from JSON
2. Filters out short noise formulas
3. Builds a dual-hash index (Latex-based and MathML-based)
4. Saves the index to disk
"""

import json
import logging
from pathlib import Path
import sys

# ç¡®ä¿èƒ½å¯¼å…¥é¡¹ç›®ä¸­çš„æ¨¡å—
sys.path.insert(0, str(Path(__file__).parent.parent))

# from retrieval.approach0_hash import Approach0HashIndex
from retrieval.indexer import FormulaIndexer
from retrieval.approach0_hash import DualHashGenerator

# ========== Logging Setup ==========
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def load_formulas(path):
    """
    åŠ è½½ç”± prepare_combined_v2.py ç”Ÿæˆçš„è”åˆå…¬å¼åº“
    """
    logger.info(f"ğŸ“‚ Loading combined formulas from {path}")
    
    with open(path, 'r', encoding='utf-8') as f:
        # è¿™é‡Œçš„ raw_formulas æ˜¯ä¸€ä¸ª Dict[visual_id, {formula_id, latex, mathml_skel}]
        formulas = json.load(f)
    
    logger.info(f"âœ… Loaded {len(formulas):,} formulas")
    return formulas

def build_index(formulas):
    """
    æ„å»ºåŒé‡å“ˆå¸Œç´¢å¼•
    """
    logger.info("ğŸ”§ Building dual-hash index (Latex + MathML)...")
    
    index = Approach0HashIndex()
    
    indexed_count = 0
    skipped_count = 0
    
    # éå†å…¬å¼å­—å…¸
    for i, (fid, formula_data) in enumerate(formulas.items()):
        latex = formula_data.get('latex', '')
        
        # âœ… ä¼˜åŒ–ï¼šè¿‡æ»¤æ‰é•¿åº¦å°äº 3 çš„å™ªå£°å…¬å¼ï¼ˆå¦‚å•ä¸ªç®—å­ã€å•ä¸ªå˜é‡ï¼‰
        # è¿™èƒ½æ˜¾è‘—å‡å°ç´¢å¼•ä½“ç§¯å¹¶æå‡æœç´¢è´¨é‡
        if not latex or len(str(latex)) < 3:
            skipped_count += 1
            continue
            
        # âœ… å…³é”®æ“ä½œï¼šå°†å®Œæ•´çš„ formula_data ä¼ é€’ç»™ add æ–¹æ³•
        # å†…éƒ¨é€»è¾‘ä¼šè‡ªåŠ¨å¤„ç† formula_data["mathml_skel"] ç”¨äºç”Ÿæˆé«˜ç²¾åº¦å“ˆå¸Œ
        index.add(formula_data)
        indexed_count += 1
        
        # è¿›åº¦æ˜¾ç¤º
        if (indexed_count) % 100000 == 0:
            logger.info(f"   Processed {i+1}/{len(formulas)} formulas...")
    
    logger.info(f"âœ… Indexing complete!")
    logger.info(f"   - Total indexed: {indexed_count:,}")
    logger.info(f"   - Total skipped (noise): {skipped_count:,}")
    return index

def main():
    logger.info("=" * 60)
    logger.info("Step 2: Building Dual-Hash Structural Index")
    logger.info("=" * 60)
    
    # è¾“å…¥è·¯å¾„
    input_path = "data/processed/formulas.json"
    if not Path(input_path).exists():
        logger.error(f"âŒ Input file not found: {input_path}")
        logger.error("   Please run: python scripts/prepare_combined_v2.py first.")
        return
    
    # 1. åŠ è½½å…¬å¼æ•°æ®
    formulas = load_formulas(input_path)
    
    # 2. æ„å»ºç´¢å¼•
    index = build_index(formulas)
    
    # 3. ä¿å­˜ç´¢å¼•æ–‡ä»¶
    output_dir = Path("artifacts")
    output_dir.mkdir(exist_ok=True)
    output_path = output_dir / "approach0_index.pkl"
    
    logger.info(f"ğŸ’¾ Saving dual-hash index to {output_path}")
    index.save(str(output_path))
    
    # 4. ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
    try:
        report = index.collision_report()
        logger.info("\n" + "=" * 30)
        logger.info("ğŸ“Š Index Statistics")
        logger.info("-" * 30)
        logger.info(f"Total buckets: {report['total_buckets']:,}")
        logger.info(f"Avg bucket size: {report['avg_bucket_size']:.2f}")
        logger.info(f"Collision rate: {report['collision_rate']:.2%}")
        logger.info("=" * 30)
    except AttributeError:
        # å¦‚æœ Approach0HashIndex ä¸­æ²¡å†™è¿™ä¸ªæ–¹æ³•ï¼Œåˆ™è·³è¿‡
        pass

    logger.info("\nâœ… Index building complete! Next: python scripts/run_eval.py")

if __name__ == "__main__":
    main()
