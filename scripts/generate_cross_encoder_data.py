import json
import random
from tqdm import tqdm
from evaluation.final_hybrid_evaluator import HybridEvaluator

# é…ç½®å‚æ•°
OUTPUT_FILE = "data/train_cross_encoder.jsonl"
NEGATIVES_PER_QUERY = 5  # æ¯ä¸ª Query åŒ¹é… 5 ä¸ªéš¾è´Ÿæ ·æœ¬
MAX_QUERIES = 500        # ç”¨äºè®­ç»ƒçš„æŸ¥è¯¢æ•°ï¼ˆå»ºè®®å…ˆç”¨å…¨éƒ¨å·²æ ‡æ³¨æŸ¥è¯¢ï¼‰

def generate_data():
    print("ğŸš€ å¯åŠ¨ Day 1ï¼šéš¾è´Ÿæ ·æœ¬æŒ–æ˜æµæ°´çº¿...")
    
    # 1. åŠ è½½èµ„æº
    evaluator = HybridEvaluator()
    with open("data/processed/formulas.json", 'r') as f:
        corpus = json.load(f)
    with open("data/processed/relevance_labels.json", 'r') as f:
        relevance = json.load(f)
    with open("data/processed/queries_full.json", 'r') as f:
        queries = json.load(f)

    train_data = []
    
    # 2. éå†å¸¦æœ‰æ ‡æ³¨çš„æŸ¥è¯¢
    annotated_qids = [qid for qid in queries.keys() if qid in relevance]
    
    for qid in tqdm(annotated_qids[:MAX_QUERIES], desc="Mining Hard Negatives"):
        q_latex = queries[qid]
        gt_ids = set(str(k) for k in relevance[qid].keys())
        
        if not gt_ids:
            continue

        # --- æŒ–æ˜æ­£æ ·æœ¬ ---
        for pos_id in gt_ids:
            if pos_id in corpus:
                train_data.append({
                    "texts": [q_latex, corpus[pos_id]],
                    "label": 1
                })

        # --- æŒ–æ˜éš¾è´Ÿæ ·æœ¬ (æ ¸å¿ƒé€»è¾‘) ---
        # è¿è¡Œç°æœ‰çš„æ£€ç´¢ç³»ç»Ÿï¼Œå– Top-50
        results = evaluator.search_single(q_latex)[:50]
        
        hard_negs = []
        for res_id in results:
            # å¦‚æœè¯¥ç»“æœä¸åœ¨çœŸå€¼åº“é‡Œï¼Œå®ƒå°±æ˜¯ä¸€ä¸ªâ€œéš¾è´Ÿæ ·æœ¬â€
            if res_id not in gt_ids and res_id in corpus:
                hard_negs.append(corpus[res_id])
            
            if len(hard_negs) >= NEGATIVES_PER_QUERY:
                break
        
        for neg_latex in hard_negs:
            train_data.append({
                "texts": [q_latex, neg_latex],
                "label": 0
            })

    # 3. ä¿å­˜ä¸º JSONL æ ¼å¼ï¼ˆæ–¹ä¾¿æµå¼è¯»å–è®­ç»ƒï¼‰
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        for entry in train_data:
            f.write(json.dumps(entry, ensure_ascii=False) + "\n")
            
    print(f"\nâœ… Day 1 å®Œæˆï¼å…±ç”Ÿæˆ {len(train_data)} æ¡è®­ç»ƒå¯¹ã€‚")
    print(f"ğŸ“¦ æ•°æ®å·²ä¿å­˜è‡³: {OUTPUT_FILE}")

if __name__ == "__main__":
    generate_data()