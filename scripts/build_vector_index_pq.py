import json
import torch
import faiss
import numpy as np
from transformers import AutoTokenizer, AutoModel
from tqdm import tqdm
from pathlib import Path
import json
import os

# --- é…ç½® ---
MODEL_NAME = "witiko/mathberta"
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
BATCH_SIZE = 128  # 3090 å»ºè®®è®¾ä¸º 128 æˆ– 256
ARTIFACTS_DIR = Path("artifacts")
INDEX_PATH = ARTIFACTS_DIR / "vector_index_pq.faiss"
MAPPING_PATH = ARTIFACTS_DIR / "vector_id_mapping_pq.json"

class MathVectorEngine:
    def __init__(self):
        print(f"æ­£åœ¨åŠ è½½æ¨¡å‹ {MODEL_NAME} åˆ° {DEVICE}...")
        self.tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
        self.model = AutoModel.from_pretrained(MODEL_NAME).to(DEVICE)
        self.model.eval()

    def encode(self, latex_list):
        inputs = self.tokenizer(latex_list, padding=True, truncation=True, 
                                 max_length=128, return_tensors="pt").to(DEVICE)
        with torch.no_grad():
            outputs = self.model(**inputs)
            # å– CLS å‘é‡
            embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()
        return embeddings

def build_index():
    ARTIFACTS_DIR.mkdir(exist_ok=True)
    
    # 1. åŠ è½½æ•°æ® ID
    print("ğŸ“– æ­£åœ¨è¯»å– formulas.json ...")
    with open("data/processed/formulas.json", 'r', encoding='utf-8') as f:
        corpus = json.load(f)
    
    # ä¿®æ”¹è¿™é‡Œï¼šå¼ºåˆ¶åªå–å‰ 10 ä¸‡æ¡ï¼ˆå¤§çº¦ç›¸å½“äº 1 ä¸ªåˆ†ç‰‡çš„é‡ï¼‰è¿›è¡Œæµ‹è¯•
    all_fids = list(corpus.keys())
    fids = list(corpus.keys())
    # fids = all_fids[:1000000] 
    print(f"ğŸ§ª æµ‹è¯•æ¨¡å¼ï¼šä»…å¤„ç†å‰ {len(fids)} æ¡å…¬å¼")
    
    # 
    
    engine = MathVectorEngine()
    dimension = 768
    
    # 2. åˆå§‹åŒ–æˆ–åŠ è½½ç´¢å¼•
    if not INDEX_PATH.exists():
        print("ğŸ—ï¸ æ­£åœ¨å‡†å¤‡è®­ç»ƒ PQ å‹ç¼©ç´¢å¼•...")
        quantizer = faiss.IndexFlatIP(dimension)
        # m=96 (768/8), nlist=1024
        index = faiss.IndexIVFFlat(quantizer, dimension, 1024, faiss.METRIC_INNER_PRODUCT)
        
        # --- æ ¸å¿ƒä¿®å¤ï¼šåˆ†æ‰¹æå–è®­ç»ƒæ•°æ® ---
        train_size = min(100000, len(fids))
        print(f"ğŸ§ª æ­£åœ¨ç¼–ç  {train_size} æ¡æ•°æ®ç”¨äºè®­ç»ƒç´¢å¼•...")
        train_embs = []
        for i in tqdm(range(0, train_size, BATCH_SIZE), desc="è®­ç»ƒæ•°æ®ç¼–ç "):
            batch_fids = fids[i : i + BATCH_SIZE]
            batch_latex = [corpus[fid]['latex_norm'] for fid in batch_fids]
            emb = engine.encode(batch_latex)
            faiss.normalize_L2(emb)
            train_embs.append(emb)
        
        train_data = np.vstack(train_embs)
        print("âš™ï¸ æ­£åœ¨è®­ç»ƒèšç±»ä¸­å¿ƒ (æ­¤æ­¥ä»…éœ€ CPU/GPU ç‰‡åˆ»)...")
        index.train(train_data)
        del train_data
        del train_embs
        saved_fids = []
    else:
        print("ğŸ”„ åŠ è½½ç°æœ‰ç´¢å¼•ä»¥ç»§ç»­...")
        index = faiss.read_index(str(INDEX_PATH))
        with open(MAPPING_PATH, 'r') as f:
            saved_fids = json.load(f)

    # 3. å¾ªç¯ç¼–ç ä¸æ·»åŠ 
    print(f"ğŸš€ å¼€å§‹å‘é‡åŒ– (å‰©ä½™: {len(fids) - index.ntotal:,} æ¡)...")
    start_idx = index.ntotal
    
    pbar = tqdm(total=len(fids), initial=start_idx, desc="PQ ç¼–ç ä¸­")
    
    for i in range(start_idx, len(fids), BATCH_SIZE):
        batch_fids = fids[i : i + BATCH_SIZE]
        batch_latex = [corpus[fid]['latex_norm'] for fid in batch_fids]
        
        try:
            emb = engine.encode(batch_latex)
            faiss.normalize_L2(emb)
            index.add(emb)
            saved_fids.extend(batch_fids)
            
            # æ¯ 10 ä¸‡æ¡ä¿å­˜ä¸€æ¬¡ç£ç›˜
            if len(saved_fids) % 100000 == 0:
                faiss.write_index(index, str(INDEX_PATH))
                with open(MAPPING_PATH, 'w') as f:
                    json.dump(saved_fids, f)
            
            pbar.update(len(batch_latex))
        except Exception as e:
            print(f"è·³è¿‡æ‰¹æ¬¡ {i} ç”±äºé”™è¯¯: {e}")
            continue
            
    # æœ€ç»ˆä¿å­˜
    faiss.write_index(index, str(INDEX_PATH))
    with open(MAPPING_PATH, 'w') as f:
        json.dump(saved_fids, f)
    print(f"âœ… å®Œæˆï¼æœ€ç»ˆç´¢å¼•å¤§å°: {index.ntotal:,}")

if __name__ == "__main__":
    build_index()