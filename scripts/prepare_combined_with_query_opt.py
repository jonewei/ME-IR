import json
import csv
import sys
import xml.etree.ElementTree as ET
from pathlib import Path
import logging
import re
from tqdm import tqdm

# âœ… è°ƒå¤§å­—æ®µé™åˆ¶
csv.field_size_limit(sys.maxsize)

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def clean_mathml(xml_str):
    if not xml_str: return ""
    xml_str = re.sub(r'\s+[a-z]+="[^"]+"', '', xml_str)
    tags = re.findall(r'<([a-zA-Z0-9]+)', xml_str)
    ignored_tags = {'math', 'semantics', 'annotation', 'mstyle', 'mrow'}
    return ",".join([t for t in tags if t.lower() not in ignored_tags])

def normalize_visual_id(vid):
    """å°† q_6 ç»Ÿä¸€è½¬ä¸º 6"""
    if not vid: return ""
    return str(vid).lower().replace('q_', '').strip()

def process_arqmath_data(corpus_shards=5):
    data_dir = Path("data/arqmath3")
    xml_path = data_dir / "Topics_Task2_2022_V0.1.xml"
    opt_dir = data_dir / "opt_representation_v3"
    latex_dir = data_dir / "latex_representation_v3"
    
    # 1. è§£æ XML æ˜ å°„ (B.301 -> q_6)
    tree = ET.parse(xml_path)
    qid_to_target_vid = {}
    qid_to_latex = {}
    for topic in tree.getroot().findall('.//Topic'):
        qid = topic.get('number')
        vid = topic.find('.//Formula_Id').text
        latex = topic.find('.//Latex').text
        qid_to_target_vid[qid] = normalize_visual_id(vid)
        qid_to_latex[qid] = latex.strip() if latex else ""
    
    target_vids = set(qid_to_target_vid.values())
    query_mathml_map = {}
    formulas_corpus = {}
    
    opt_files = sorted(opt_dir.glob("*.tsv"))
    latex_files = sorted(latex_dir.glob("*.tsv"))

    # ğŸš€ ç¬¬ä¸€é˜¶æ®µï¼šæ‰«ææ‰€æœ‰ 101 ä¸ªåˆ†ç‰‡ï¼Œä»…ä¸ºæ•è·æŸ¥è¯¢å…¬å¼çš„ MathML (é€šè¿‡ visual_id)
    logger.info("ğŸ” æ­£åœ¨å…¨é‡æ‰«æ 101 ä¸ªåˆ†ç‰‡ä»¥æ•è·æŸ¥è¯¢å…¬å¼çš„ç»“æ„...")
    for f_path in tqdm(opt_files, desc="Scanning for queries"):
        with open(f_path, 'r', encoding='utf-8') as f:
            reader = csv.reader(f, delimiter='\t')
            next(reader)
            for row in reader:
                if len(row) >= 9:
                    row_vid = normalize_visual_id(row[6]) # ç¬¬ä¸ƒåˆ— visual_id
                    if row_vid in target_vids:
                        skel = clean_mathml(row[8])
                        for qid, t_vid in qid_to_target_vid.items():
                            if row_vid == t_vid:
                                query_mathml_map[qid] = skel
        if len(query_mathml_map) == len(qid_to_target_vid): break

    # ğŸš€ ç¬¬äºŒé˜¶æ®µï¼šæ„å»ºè¯­æ–™åº“ (é€šè¿‡ id åˆ—ä½œä¸º Key)
    logger.info(f"ğŸ“¦ æ­£åœ¨æ„å»ºå‰ {corpus_shards} ä¸ªåˆ†ç‰‡çš„è¯­æ–™åº“...")
    for i in range(min(corpus_shards, len(opt_files))):
        o_path = opt_files[i]
        l_path = latex_files[i]
        
        # å¤„ç† OPT (Key æ˜¯ id)
        with open(o_path, 'r', encoding='utf-8') as f:
            reader = csv.reader(f, delimiter='\t')
            next(reader)
            for row in reader:
                if len(row) >= 9:
                    fid = row[0].strip() # âœ… ç¬¬ä¸€åˆ— id
                    formulas_corpus[fid] = {"formula_id": fid, "mathml_skel": clean_mathml(row[8])}

        # å¤„ç† LaTeX (Key æ˜¯ id)
        with open(l_path, 'r', encoding='utf-8') as f:
            reader = csv.reader(f, delimiter='\t')
            next(reader)
            for row in reader:
                if len(row) >= 9:
                    fid = row[0].strip() # âœ… ç¬¬ä¸€åˆ— id
                    if fid in formulas_corpus:
                        formulas_corpus[fid]["latex"] = row[8].strip()

    # ä¿å­˜ç»“æœ
    out_dir = Path("data/processed")
    out_dir.mkdir(exist_ok=True)
    with open(out_dir / "formulas.json", 'w') as f:
        json.dump(formulas_corpus, f, indent=2)
    
    q_full = {qid: {"query_id": qid, "latex": qid_to_latex[qid], "mathml_skel": query_mathml_map.get(qid, "")} for qid in qid_to_latex}
    with open(out_dir / "queries_full.json", 'w') as f:
        json.dump(q_full, f, indent=2)
    
    with open(out_dir / "queries.json", 'w') as f:
        json.dump({qid: data["latex"] for qid, data in q_full.items()}, f, indent=2)

    logger.info(f"âœ… å®Œæˆï¼æ•è·ç‡: {len(query_mathml_map)}/100, è¯­æ–™åº“: {len(formulas_corpus)} æ¡")

if __name__ == "__main__":
    process_arqmath_data(corpus_shards=5)
